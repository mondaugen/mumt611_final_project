\documentclass[72pt]{article}
\usepackage[a4paper,margin=1in,landscape]{geometry}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{float}
\DeclareMathSizes{72}{72}{72}{72}
\DeclareGraphicsExtensions{.eps}
%\graphicspath{{../plots/}{.}}
\begin{document}

\begin{Huge}
\title{Monaural Singing Voice Separation Using Non-Negative Matrix 
Factorization}
\date{April 29th, 2015}
\author{Nicholas Esterer}
\maketitle

\newpage

\section*{Motivation: Separating the Singing Voice from Instrumental
Accompaniment}
Applications:
\begin{itemize}
    \item Melody extraction
    \item Song recognition    
    \item Singer identification
\end{itemize}

\newpage

\section*{Features of the Singing Voice}
\begin{itemize}
    \item Compared to harmonic instrumental accompaniment, the singing voice
            exhibits a spectrum whose frames vary over time whereas instrumental
            accompaniment remains static.
    \item Compared to percussive instrumental accompaniment, the singing voice
            spectrum does not vary as greatly over time as brief percussive
            impulses.
\end{itemize}

\newpage

\section*{Why?}
\begin{itemize}
    \item In Marin and McAdams (1991), studies showed that modulating the
            frequency and vowel of a synthesized tone increased its perceived
            prominence among unmodulated vowels.
    \item This suggest that singers modulate frequency and amplitude of the
voice to have prominence over other harmonic instruments.
\end{itemize}

\newpage

\section*{Characteristics of Singing Voice Spectrograms}
\begin{itemize}
    \item According to Zhu et al. (2013), because the singing voice exhibits
some frequency and amplitude modulation, taking a long-window spectrogram of the
voice will show excitation in different bins of adjacent frames, while the same
spectrogram of the more static harmonic accompaniment will show adjacent frames
sharing prominent bins.

\newpage

% Insert long window slides of voice and instrument

\begin{figure}[H]
    \centering
    \includegraphics{maybe_if_8192_4096}
\end{figure}

\newpage

\begin{figure}[H]
    \centering
    \includegraphics{sax_accord_8192_4096}
\end{figure}

\newpage

    \item Because the singing voice exhibits less frequency and amplitude
    modulation than percussive instruments, taking a short window spectrogram of
    the singing voice will show excitation of the same bin in adjacent frames
    whereas the spectrogram of a percussive sound will not share prominent bins
    among adjacent frames.
\end{itemize}

\newpage

% Insert short window slides of voice and instrument

\begin{figure}[H]
    \centering
    \includegraphics{maybe_if_1024_512}
\end{figure}

\newpage

\begin{figure}[H]
    \centering
    \includegraphics{sax_accord_1024_512.eps}
\end{figure}

\newpage


\section*{Technique}
We use a technique documented in Zhu et al. (2013)
\begin{itemize}
    \item These observations motivate a technique that removes those elements of
the spectrogram that are not deemed to stem from the voice:
    \begin{itemize}
        \item Remove spectra whose prominent bins are non-varying on a
long-window spectrogram.
        \item Remove spectra whose prominent bins are varying on a short-window
spectrogram.
    \end{itemize}
\end{itemize}

\newpage
\begin{itemize}
    \item Of course, the singing voice and the instrumental accompaniment will often be
    simultaneous in the recording and their respective spectra also simultaneous.
    \item We would like to separate these spectra.
    \item Hennequin et al. (2011), among others, demonstrated that non-negative
matrix factorization (NMF) is good at separating spectrograms into a set of basis
vectors \( \mathbf{B} \) and their time-varying gains \( \mathbf{G} \).
    \item We use NMF on both the long- and short-window spectrograms to compute
basis spectra.
    \item We then identify spectra stemming from harmonic instruments and
percussive instruments, respectively.
\end{itemize}

\newpage

The following calculation is used to measure the amount of spectral
discontinuity in the \( j^{th} \) column of \( \mathbf{B} \) (a basis vector) in
order to identify spectra stemming from harmonic instruments

\begin{equation} \label{eq:discontinuity_freq}
d_\sigma(\mathbf{B}^j) =
\frac{\sum\limits_{k=2}^{K}(\mathbf{B}_{k,j}-\mathbf{B}_{k-1,j})^2}{
    \sum\limits_{k=1}^{K}(\mathbf{B}_{k,j}^{2})}
\end{equation}

where \( K \) is the number of bins in the spectrogram.

\newpage

Similarly, the following calculation is used to measure the amount of
discontinuity in the activation gains in the \( j^{th} \) row of \(
\mathbf{G} \) in order to identify spectra stemming from percussive instruments

\begin{equation} \label{eq:discontinuity_gain}
d_\tau(\mathbf{G}^j) =
\frac{\sum\limits_{t=2}^{T}(\mathbf{G}_{j,t}-\mathbf{G}_{j,t-1})^2}{
    \sum\limits_{t=1}^{T}(\mathbf{G}_{j,t}^{2})}
\end{equation}

where \( T \) is the number of frames in the spectrogram.

\newpage

\section*{The Computation of Spectral Bases}
Given a spectrogram \( \mathbf{X} \) of \( K \) bins and \( T \) frames, NMF
will find an approximate factorization

\[ \mathbf{X} \approx \mathbf{B}\mathbf{G} \]

where \( \mathbf{B} \) is a matrix of \( K \) rows and \( J \) columns and \(
\mathbf{G} \) is a matrix of \( J \) rows and \( T \) columns.

\newpage

When using the Kullback-Leibler divergence and interpreting it as a
\(\beta\)-divergence where \(\beta = 1 \), according to Hennequin et al.
(2011b), the divergence is non-increasing when using the following update rules:

\[ \mathbf{B} \gets
\mathbf{B}.\frac{\frac{\mathbf{X}}{\mathbf{B}\mathbf{G}}\mathbf{G}^T}
    {\mathbf{1}\mathbf{G}^T}
\]

\[ \mathbf{G} \gets
\mathbf{G}.\frac{\mathbf{B}^T\frac{\mathbf{X}}{\mathbf{B}\mathbf{G}}}
    {\mathbf{B}^{T}\mathbf{1}}
\]

Where \( \bigcirc.\bigcirc \) indicates element-wise multiply and \( \frac{\bigcirc}{\bigcirc} \) indicates
element-wise division.

\newpage

Once the basis components have been identified using
\eqref{eq:discontinuity_freq} and \eqref{eq:discontinuity_gain} they are removed
from the magnitude spectrogram \( \mathbf{X} \) creating \( \tilde{\mathbf{X}} \) by
first forming matrices \( \tilde{\mathbf{B}} \) and \( \tilde{\mathbf{G}} \) from those rows and
columns deemed as too spectrally discontinuous, i.e., \( d_\sigma(\mathbf{B}) >
\theta_s \) and \( d_\tau(\mathbf{G}) > \theta_t \), some thresholds of
discontinuity. Their product is then subtracted from \( \mathbf{X} \) and the
resulting magnitude clamped at 0.

\[
\mathbf{\tilde{X}} = \max(0,\mathbf{X} -
\mathbf{\tilde{B}}\mathbf{\tilde{G}})
\]

\newpage

\section*{Implementation}
\begin{itemize}
    \item Spectrogram of signal computed with C program
        \begin{itemize}
            \item performs short-time Fourier transform (STFT),
            \item preserves phase information.
        \end{itemize}
    \item \textit{Octave}\footnote{www.gnu.org/software/octave/} used to carry
        out NMF and remove discontinuous spectra.
    \item Signal resynthesized using C program
        \begin{itemize}
            \item performs inverse STFT,
            \item uses original phase information with new magnitudes.
        \end{itemize}
    \item \textit{Sox}\footnote{http://sox.sourceforge.net/} used to do format
        and sample rate conversion.
\end{itemize}

\newpage

\section*{Results}
\begin{itemize}
    \item Works qualitatively.
    \item When using authors' dataset and parameter recommendations, some
encouraging results are obtained.
    \item The authors in Zhu et al. (2013) state ``Informal listening [...]
showed that our algorithm can separate singing voice and music accompaniment to
some degree."
\end{itemize}

\newpage

\section*{Issues and Criticism}
\begin{itemize}
    \item Algorithm rather slow.
    \item Suspect choice of parameters highly dependent upon dataset.
    \item Choice of parameters also seems to depend on length of input signal.
\end{itemize}

\newpage

\section*{Improvements}
\begin{itemize}
    \item Try to learn a good set of parameters using machine learning
techniques.
    \item Rather than totally elminating components, try simply attenuating
them. This could reduce the presence of artifacts.
    \item Try to further exploit the perceptual results of Marin and McAdams
(1991) to better track the vocal part.
\end{itemize}

\end{Huge}

\newpage
\section*{Bibliography}
\begin{flushleft}
C. Marin and S. McAdams, ``Segregation of concurrent sounds. II: Effects of
spectral envelope tracing, frequency modulation coherence, and frequency
modulation width," in \textit{J. Acoust. Soc. Am.}, Vol 89, No. 1, January 1991.
\par
B. Zhu, W. Lei, R. Li, and X Xue, ``Multi-Stage Non-Negative Matrix
Factorization for Monaural Singing Voice Separation," in \textit{IEEE Trans.
Audio, Speech, Language Proc.}, Vol. 21, No. 10, October 2013.
\par
R. Hennequin, R. Badeau, and B. David, ``NMF With Time-Frequency Activations to
Model Nonstationary Audio Events," in \textit{IEEE Trans.
Audio, Speech, Language Proc.,}, Vol. 19, No. 4, May 2011.
\par
R. Hennequin, B. David, and R. Badeau ``Beta-Divergence as a Subclass of Bregman
Divergence," in \textit{IEEE Sig. Proc. Letters}, Vol. 18, No. 2, February 2011.
\end{flushleft}

\end{document}
